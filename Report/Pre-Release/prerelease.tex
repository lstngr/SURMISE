\documentclass[10pt,a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{cleveref}
\author{Louis Stenger}
\title{N-Body Gravity Solver (Pre-Release)}
\subtitle{Parallel and High-Performance Computing}
\begin{document}
	\maketitle
	\section{Contents of the Pre-Release}
	This document is part of the pre-release for a $N$-body gravity problem solver. The code can be cloned using the URL found at the following address,\\\texttt{https://c4science.ch/source/SuRMISe/repository/master/}.\\ Below, we briefly remind the aim of the project below, discuss the current implementation choice, investigate early results and roughly describe the work that remains to be performed.
	
	\subsection{Remainder of the Project's Scope}
	The initial aim of the project was the implementation of a $N$-body solver for a gravity problem, using the fast-multipole method (FMM, a tree-based method) in two dimensions over a square domain. Ultimately, the code will be parallelized using the MPI library. In its current implementation, the code performs the computation of forces using the Barnes-Hut algorithm for simplicity (the FMM will be implemented if deemed relevant and possible).
	
	\subsection{Code Design} \label{sec:codedesign}
	The following (relevant) data structures are used by the code,
	\begin{itemize}
		\item \verb|Particle|: \emph{Structure} storing the mass, 2D position/velocity/force of a massive particle of the simulation (all double). An additional integer field is used to store a unique identifier of the particle (shall they get mixed in memory, which might happen later with the MPI implementation).
		\item \verb|Node|(s): Generic \emph{class} describing a (square) region of the physical space. It will be used in the quad-tree decomposition of the simulated area. A large array of methods is associated with this class. \verb|Node| is inherited by two child classes,
		\begin{enumerate}
			\item \verb|RootNode|: This node is located at the top of the tree. It is instantiated by the user in the main() and partly redefines methods from \verb|Node| so that they ``launch'' computational tasks (such as tree decomposition, force computation, particles updates) over the whole tree.
			\item \verb|LeafNode|: Located at the bottom of the tree, these nodes offer an extensible particle storage (std::vector) and redefine methods from \verb|Node| so to work directly with their particle's data.
		\end{enumerate}
		\item \verb|SConfig|: A structure containing the simulation's parameters, which is initialized by reading input files at the very beginning of the simulation.
	\end{itemize}
	A typical has the following structure.
	\begin{enumerate}
		\item \textbf{Initialization}. Input files (generated by hand, or with the provided MATLAB scripts) are read, and relevant parameters (number of particles, domain size, etc.) are loaded in a \verb|SConfig| object. When initial conditions are read, \verb|Particle| objects are \emph{dynamically} allocated, and pointers to those are stored in the \verb|SConfig| object (which's destructor is responsible for clearing their memory, check with valgrind).
		\item \textbf{Tree Instantiation}. A \verb|RootNode| variable is created and the \verb|SConfig| structure is passed to it.
		\item \textbf{Simulation}. This step is initiated by a call to \verb|RootNode::Run()|, and performs the following steps.
		\begin{enumerate}
			\item An initial tree decomposition. We note the structure is \emph{NOT adaptive} and \emph{fixed}; each tree level consists of an array of \verb|Node| objects. The two following items are repeated for the requested amount of iterations. Children nodes are dynamically allocated and deleted at the end of the parent's life.
			\item A force computation routine (\verb|Node::TimeEvolution|) performs an upwards sweep in the tree (propagation of the total mass and reset previous forces), followed by a downwards sweep (coarse force computation between nodes and finer one at leaf level, particle-particle interactions\footnote{Unless these are located too close to one another (arbitrary distance), in which case the interaction is omitted for stability reasons (avoid slingshots).}). At the end of this procedure, each Particle object stores the force that needs to be applied at the forthcoming time step.
			\item An evolution routine updating the positions and velocities of the particles based on the previous step. At the end of the displacement, it is checked whether the particle needs to be reassigned to another node.
		\end{enumerate}
	\end{enumerate}
	
	At this point (see the Doxygen documentation and the code, it will for sure be clearer), we note that
	\begin{itemize}
		\item The use of pointers allows to easily refer to objects in the simulation, but do not account for their ``physical'' locality (two particles can be very close in memory, as initialized when reading the input file, but at opposite ends of the simulated domain). This may result in lots of cache misses once the requested simulations reach a large size.
		\item The proposed structure involves a lot of recursive calls for force computation and time evolution mechanisms. We heavily depend on the compiler's smartness on performance related issues.
		\item Particles escaping the simulation domain are not reassigned. When looking at the output, it appears they just get ``stuck'' on the borders of the domain, and this might cause large jitter in the forces of nearby masses.
	\end{itemize}
	
	\section{Early Analysis}
	We briefly investigate the behavior of the current implementation.
	\subsection{Physical Accuracy}
	The physical accuracy of the code is verified using a simple two-mass configuration, \cref{fig:two}. The exact force applied on such masses is computed Ã -posteriori with a MATLAB script, \cref{fig:delf}, we can see an erroneous jitter.
	\begin{figure}
		\centering
		\includegraphics[width=8cm]{two}
		\caption{Initial configuration. The masses are located on a 3-leveled grid of size $100\times100$ and have initial velocities of norm $\sqrt{0.02}$.}
		\label{fig:two}
	\end{figure}
	\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{delF}
	\caption{Up: Relative force error for one of the simulated particles in function of the number of temporal iterations, it. The regions it$\in[140,320]$ and $[715,790]$ have negligible errors since the particles are located in nearest neighbor cells (the force is computed using a particle-particle scheme). The points where the error ``jumps'' correspond to particle reassignments, which change the masses of the nodes, and shift the direction in which the forces are applied. Shall one have used the center of mass of the node, and not the geometrical one, to compute the coarse-level forces, no error would have been spotted.~Down: The simulated force applied to the first particle. The large intensity regions correspond to a fly-by of the two simulated objects.}
	\label{fig:delf}
	\end{figure}
	\subsection{Performance}
	I can't really dig in much more (it's 23:30 already). Summing up the analyses with \verb|perf|, that we can gladly discuss together, the compiler's optimization setting is seen to play a major role in performance increase, probably due to the recursive structure of the code. At \verb|O3|, the main bottlenecks appear when gathering properties (such as the mass) from children nodes in the tree.
	\section{Future Work}
	Very briefly, a solution to problems pinpointed in \cref{sec:codedesign} is to be provided (at least phrased).
	The Barnes-Hut routine needs to be updated to compute the force with respect to a \verb|Node|'s center of mass (instead of the geometrical one) to gain precision.
	Output mechanisms need to be investigated.
	Obviously, a parallelization strategy remains to be found, but due to the current state of the code (and of my semester), the latter remains unclear.
\end{document}